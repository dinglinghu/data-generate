#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ—¶é—´è½´æ•°æ®æŸ¥çœ‹å™¨
ç”¨äºæŸ¥çœ‹å’ŒéªŒè¯è½¬æ¢åçš„å…ƒä»»åŠ¡æ—¶é—´è½´æ•°æ®
"""

import json
import os
import glob
from datetime import datetime
from typing import Dict, List, Any


def load_timeline_data(file_path: str) -> Dict:
    """åŠ è½½æ—¶é—´è½´æ•°æ®"""
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def print_collection_summary(collection_name: str, collection_data: Dict):
    """æ‰“å°å•æ¬¡é‡‡é›†çš„æ‘˜è¦ä¿¡æ¯"""
    print(f"\nğŸ“Š {collection_name}")
    print("="*60)
    
    # åŸºæœ¬ä¿¡æ¯
    planning_period = collection_data.get('planning_period', {})
    print(f"â° è§„åˆ’å‘¨æœŸ: {planning_period.get('start_time')} â†’ {planning_period.get('end_time')}")
    print(f"â±ï¸ æŒç»­æ—¶é—´: {planning_period.get('duration_hours', 0):.2f} å°æ—¶")
    
    # å…ƒä»»åŠ¡ç»Ÿè®¡
    meta_timeline = collection_data.get('meta_task_timeline', {})
    print(f"ğŸ¯ å…ƒä»»åŠ¡æ€»æ•°: {meta_timeline.get('total_count', 0)}")
    print(f"   çœŸå®ä»»åŠ¡: {meta_timeline.get('real_task_count', 0)}")
    print(f"   è™šæ‹Ÿä»»åŠ¡: {meta_timeline.get('virtual_task_count', 0)}")
    
    # å¯è§å…ƒä»»åŠ¡ç»Ÿè®¡
    visible_timeline = collection_data.get('visible_meta_task_timeline', {})
    print(f"ğŸ‘ï¸ å¯è§ä»»åŠ¡æ€»æ•°: {visible_timeline.get('total_count', 0)}")
    print(f"   å¯è§å…ƒä»»åŠ¡: {visible_timeline.get('visible_task_count', 0)}")
    print(f"   è™šæ‹ŸåŸå­ä»»åŠ¡: {visible_timeline.get('virtual_atomic_task_count', 0)}")
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = collection_data.get('statistics', {})
    print(f"ğŸš€ å¯¼å¼¹æ•°é‡: {stats.get('missile_count', 0)}")
    print(f"ğŸ›°ï¸ å«æ˜Ÿæ•°é‡: {stats.get('satellite_count', 0)}")
    print(f"ğŸ“ˆ å¯è§ç‡: {stats.get('visibility_ratio', 0):.2%}")


def print_task_details(collection_name: str, collection_data: Dict, task_type: str = 'meta', limit: int = 5):
    """æ‰“å°ä»»åŠ¡è¯¦ç»†ä¿¡æ¯"""
    print(f"\nğŸ” {collection_name} - {task_type.upper()}ä»»åŠ¡è¯¦æƒ… (å‰{limit}ä¸ª)")
    print("-"*80)
    
    if task_type == 'meta':
        tasks = collection_data.get('meta_task_timeline', {}).get('tasks', [])
    else:
        tasks = collection_data.get('visible_meta_task_timeline', {}).get('tasks', [])
    
    for i, task in enumerate(tasks[:limit]):
        print(f"ğŸ“‹ ä»»åŠ¡ {i+1}:")
        print(f"   ç±»å‹: {task.get('type', 'N/A')}")
        if task_type == 'meta':
            print(f"   å¯¼å¼¹: {task.get('missile_id', 'N/A')}")
        else:
            print(f"   å«æ˜Ÿ: {task.get('satellite_id', 'N/A')} â†’ å¯¼å¼¹: {task.get('missile_id', 'N/A')}")
        print(f"   æ—¶é—´: {task.get('start_time', 'N/A')} â†’ {task.get('end_time', 'N/A')}")
        print(f"   æŒç»­: {task.get('duration_seconds', 0):.0f}ç§’")
        if task_type == 'meta':
            print(f"   çœŸå®: {task.get('is_real_task', False)}, è™šæ‹Ÿ: {task.get('is_virtual_task', False)}")
        print()


def print_global_statistics(data: Dict):
    """æ‰“å°å…¨å±€ç»Ÿè®¡ä¿¡æ¯"""
    print("\n" + "="*80)
    print("ğŸŒ å…¨å±€ç»Ÿè®¡ä¿¡æ¯")
    print("="*80)
    
    conversion_info = data.get('conversion_info', {})
    print(f"ğŸ”„ è½¬æ¢æ—¶é—´: {conversion_info.get('conversion_time', 'N/A')}")
    print(f"ğŸ“ æ€»é‡‡é›†æ¬¡æ•°: {conversion_info.get('total_collections', 0)}")
    print(f"âœ… æˆåŠŸè½¬æ¢: {conversion_info.get('successful_conversions', 0)}")
    
    global_stats = data.get('global_statistics', {})
    print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
    print(f"   æ€»å…ƒä»»åŠ¡æ•°: {global_stats.get('total_meta_tasks', 0)}")
    print(f"   æ€»å¯è§ä»»åŠ¡æ•°: {global_stats.get('total_visible_tasks', 0)}")
    print(f"   æ€»è™šæ‹ŸåŸå­ä»»åŠ¡æ•°: {global_stats.get('total_virtual_atomic_tasks', 0)}")
    print(f"   å”¯ä¸€å¯¼å¼¹æ•°: {global_stats.get('unique_missiles', 0)}")
    print(f"   å”¯ä¸€å«æ˜Ÿæ•°: {global_stats.get('unique_satellites', 0)}")
    print(f"   å¹³å‡å¯è§ç‡: {global_stats.get('average_visibility_ratio', 0):.2%}")


def analyze_timeline_data(file_path: str):
    """åˆ†ææ—¶é—´è½´æ•°æ®"""
    print("ğŸ” åŠ è½½æ—¶é—´è½´æ•°æ®...")
    data = load_timeline_data(file_path)
    
    # æ‰“å°å…¨å±€ç»Ÿè®¡
    print_global_statistics(data)
    
    # æ‰“å°æ¯æ¬¡é‡‡é›†çš„æ‘˜è¦
    collections = data.get('collections', {})
    collection_names = sorted(collections.keys())
    
    print(f"\nğŸ“‹ é‡‡é›†æ‘˜è¦ (å…±{len(collection_names)}æ¬¡):")
    for collection_name in collection_names:
        collection_data = collections[collection_name]
        print_collection_summary(collection_name, collection_data)
    
    # æ‰“å°æœ€åä¸€æ¬¡é‡‡é›†çš„è¯¦ç»†ä¿¡æ¯
    if collection_names:
        last_collection = collection_names[-1]
        last_data = collections[last_collection]
        
        print(f"\nğŸ” æœ€åä¸€æ¬¡é‡‡é›†è¯¦ç»†ä¿¡æ¯: {last_collection}")
        print_task_details(last_collection, last_data, 'meta', 3)
        print_task_details(last_collection, last_data, 'visible', 5)


def main():
    """ä¸»å‡½æ•°"""
    # æŸ¥æ‰¾æœ€æ–°çš„æ—¶é—´è½´æ•°æ®æ–‡ä»¶
    # data_dir = 'output/data'
    data_files = glob.glob('output/rolling_collections/*/data/meta_task_data.json')
    
    if not timeline_files:
        print("âŒ æœªæ‰¾åˆ°æ—¶é—´è½´æ•°æ®æ–‡ä»¶")
        return
    
    # ä½¿ç”¨æœ€æ–°çš„æ–‡ä»¶
    latest_file = sorted(timeline_files)[-1]
    file_path = os.path.join(data_dir, latest_file)
    
    print(f"ğŸ“ ä½¿ç”¨æ•°æ®æ–‡ä»¶: {latest_file}")
    analyze_timeline_data(file_path)


if __name__ == "__main__":
    main()
