#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å«æ˜Ÿä½ç½®åŒæ­¥å™¨
ä¸ºæ¯ä¸ªå¯è§å…ƒä»»åŠ¡åŒæ­¥å«æ˜Ÿåœ¨ä»»åŠ¡æ—¶é—´æ®µå†…çš„ä½ç½®ä¿¡æ¯
"""

import logging
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
import json
import asyncio
import concurrent.futures
import threading
from functools import partial

logger = logging.getLogger(__name__)

class SatellitePositionSynchronizer:
    """å«æ˜Ÿä½ç½®åŒæ­¥å™¨"""
    
    def __init__(self, stk_manager, time_manager, config_manager=None):
        """
        åˆå§‹åŒ–å«æ˜Ÿä½ç½®åŒæ­¥å™¨

        Args:
            stk_manager: STKç®¡ç†å™¨å®ä¾‹
            time_manager: æ—¶é—´ç®¡ç†å™¨å®ä¾‹
            config_manager: é…ç½®ç®¡ç†å™¨å®ä¾‹
        """
        self.stk_manager = stk_manager
        self.time_manager = time_manager

        # è·å–é…ç½®
        if config_manager:
            from ..utils.config_manager import get_config_manager
            self.config_manager = config_manager
        else:
            from ..utils.config_manager import get_config_manager
            self.config_manager = get_config_manager()

        # è·å–ä½ç½®åŒæ­¥é…ç½®
        meta_task_config = self.config_manager.config.get("meta_task_management", {})
        position_sync_config = meta_task_config.get("position_sync", {})

        # ä½ç½®é‡‡æ ·é…ç½®
        self.position_sample_interval = position_sync_config.get("sample_interval_seconds", 30)
        self.max_samples_per_task = position_sync_config.get("max_samples_per_task", 20)
        self.enable_statistics = position_sync_config.get("enable_statistics", True)
        self.export_detailed_data = position_sync_config.get("export_detailed_data", False)

        # å¹¶å‘é…ç½®
        self.enable_concurrent = position_sync_config.get("enable_concurrent", True)
        self.max_workers = position_sync_config.get("max_workers", 4)
        self.concurrent_batch_size = position_sync_config.get("concurrent_batch_size", 10)
        self.stk_com_timeout = position_sync_config.get("stk_com_timeout", 30)

        # STK COMæ¥å£çº¿ç¨‹å®‰å…¨é”
        self._stk_lock = threading.Lock()

        logger.info("ğŸ›°ï¸ å«æ˜Ÿä½ç½®åŒæ­¥å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   é‡‡æ ·é—´éš”: {self.position_sample_interval}ç§’")
        logger.info(f"   æœ€å¤§é‡‡æ ·ç‚¹æ•°: {self.max_samples_per_task}")
        logger.info(f"   ç»Ÿè®¡è®¡ç®—: {'å¯ç”¨' if self.enable_statistics else 'ç¦ç”¨'}")
        logger.info(f"   å¹¶å‘å¤„ç†: {'å¯ç”¨' if self.enable_concurrent else 'ç¦ç”¨'}")
        if self.enable_concurrent:
            logger.info(f"   æœ€å¤§å·¥ä½œçº¿ç¨‹: {self.max_workers}")
            logger.info(f"   æ‰¹å¤„ç†å¤§å°: {self.concurrent_batch_size}")
    
    def synchronize_satellite_positions_for_visible_tasks(self, visible_meta_tasks: Dict[str, Any]) -> Dict[str, Any]:
        """
        ä¸ºæ‰€æœ‰å¯è§å…ƒä»»åŠ¡åŒæ­¥å«æ˜Ÿä½ç½®ï¼ˆæ”¯æŒå¹¶å‘å¤„ç†ï¼‰

        Args:
            visible_meta_tasks: å¯è§å…ƒä»»åŠ¡æ•°æ®

        Returns:
            å¢å¼ºåçš„å¯è§å…ƒä»»åŠ¡æ•°æ®ï¼ˆåŒ…å«å«æ˜Ÿä½ç½®ä¿¡æ¯ï¼‰
        """
        try:
            start_time = datetime.now()
            logger.info("ğŸ›°ï¸ å¼€å§‹ä¸ºå¯è§å…ƒä»»åŠ¡åŒæ­¥å«æ˜Ÿä½ç½®...")

            enhanced_visible_tasks = visible_meta_tasks.copy()

            # è·å–æ˜Ÿåº§å¯è§ä»»åŠ¡é›†
            constellation_visible_task_sets = enhanced_visible_tasks.get("constellation_visible_task_sets", {})

            # ğŸ”§ ä¿®å¤ï¼šç”±äºSTK COMæ¥å£çš„å¤šçº¿ç¨‹é—®é¢˜ï¼Œæš‚æ—¶ç¦ç”¨å¹¶å‘å¤„ç†
            logger.info("ğŸ”§ ä½¿ç”¨ä¸²è¡Œå¤„ç†æ¨¡å¼ï¼ˆé¿å…STK COMå¤šçº¿ç¨‹é—®é¢˜ï¼‰")
            total_tasks_processed, total_positions_collected = self._process_tasks_serially(
                constellation_visible_task_sets
            )

            # è®¡ç®—å¤„ç†æ—¶é—´
            processing_time = (datetime.now() - start_time).total_seconds()

            # æ·»åŠ åŒæ­¥ç»Ÿè®¡ä¿¡æ¯
            enhanced_visible_tasks["position_sync_metadata"] = {
                "sync_time": datetime.now().isoformat(),
                "total_tasks_processed": total_tasks_processed,
                "total_positions_collected": total_positions_collected,
                "sample_interval_seconds": self.position_sample_interval,
                "processing_time_seconds": processing_time,
                "concurrent_enabled": self.enable_concurrent,
                "max_workers": self.max_workers if self.enable_concurrent else 1,
                "sync_status": "completed"
            }

            logger.info(f"ğŸ›°ï¸ å«æ˜Ÿä½ç½®åŒæ­¥å®Œæˆ:")
            logger.info(f"   å¤„ç†ä»»åŠ¡æ•°: {total_tasks_processed}")
            logger.info(f"   é‡‡é›†ä½ç½®ç‚¹æ•°: {total_positions_collected}")
            logger.info(f"   å¤„ç†æ—¶é—´: {processing_time:.2f}ç§’")
            logger.info(f"   å¤„ç†æ¨¡å¼: {'å¹¶å‘' if self.enable_concurrent else 'ä¸²è¡Œ'}")

            return enhanced_visible_tasks

        except Exception as e:
            logger.error(f"âŒ å«æ˜Ÿä½ç½®åŒæ­¥å¤±è´¥: {e}")
            import traceback
            logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return visible_meta_tasks

    def _process_tasks_concurrently(self, constellation_visible_task_sets: Dict[str, Any]) -> Tuple[int, int]:
        """
        å¹¶å‘å¤„ç†æ‰€æœ‰å¯è§ä»»åŠ¡çš„ä½ç½®åŒæ­¥

        Args:
            constellation_visible_task_sets: æ˜Ÿåº§å¯è§ä»»åŠ¡é›†

        Returns:
            (å¤„ç†ä»»åŠ¡æ•°, é‡‡é›†ä½ç½®ç‚¹æ•°)
        """
        try:
            # æ”¶é›†æ‰€æœ‰éœ€è¦å¤„ç†çš„ä»»åŠ¡
            task_items = []

            for satellite_id, satellite_tasks in constellation_visible_task_sets.items():
                missile_tasks = satellite_tasks.get("missile_tasks", {})

                for missile_id, missile_task_data in missile_tasks.items():
                    visible_tasks = missile_task_data.get("visible_tasks", [])

                    for task in visible_tasks:
                        task_items.append((satellite_id, task))

            logger.info(f"ğŸš€ å¹¶å‘å¤„ç† {len(task_items)} ä¸ªå¯è§ä»»åŠ¡ï¼Œä½¿ç”¨ {self.max_workers} ä¸ªå·¥ä½œçº¿ç¨‹")

            total_tasks_processed = 0
            total_positions_collected = 0

            # åˆ†æ‰¹å¤„ç†ä»¥é¿å…è¿‡å¤šçš„å¹¶å‘è¿æ¥
            batch_size = self.concurrent_batch_size

            for i in range(0, len(task_items), batch_size):
                batch = task_items[i:i + batch_size]
                logger.debug(f"å¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}: {len(batch)} ä¸ªä»»åŠ¡")

                # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†å½“å‰æ‰¹æ¬¡
                with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                    # æäº¤æ‰€æœ‰ä»»åŠ¡
                    future_to_task = {
                        executor.submit(self._synchronize_position_for_task_thread_safe, satellite_id, task): (satellite_id, task)
                        for satellite_id, task in batch
                    }

                    # æ”¶é›†ç»“æœ
                    for future in concurrent.futures.as_completed(future_to_task):
                        satellite_id, task = future_to_task[future]
                        try:
                            position_data = future.result()

                            if position_data:
                                task["satellite_position_sync"] = position_data
                                total_positions_collected += len(position_data.get("position_samples", []))
                                total_tasks_processed += 1

                                logger.debug(f"âœ… ä»»åŠ¡ {task.get('task_id')} ä½ç½®åŒæ­¥å®Œæˆ")
                            else:
                                logger.warning(f"âš ï¸ ä»»åŠ¡ {task.get('task_id')} ä½ç½®åŒæ­¥å¤±è´¥")

                        except Exception as e:
                            logger.error(f"âŒ ä»»åŠ¡ {task.get('task_id')} å¤„ç†å¼‚å¸¸: {e}")

            return total_tasks_processed, total_positions_collected

        except Exception as e:
            logger.error(f"âŒ å¹¶å‘å¤„ç†å¤±è´¥: {e}")
            return 0, 0

    def _process_tasks_serially(self, constellation_visible_task_sets: Dict[str, Any]) -> Tuple[int, int]:
        """
        ä¸²è¡Œå¤„ç†æ‰€æœ‰å¯è§ä»»åŠ¡çš„ä½ç½®åŒæ­¥ï¼ˆåŸæœ‰é€»è¾‘ï¼‰

        Args:
            constellation_visible_task_sets: æ˜Ÿåº§å¯è§ä»»åŠ¡é›†

        Returns:
            (å¤„ç†ä»»åŠ¡æ•°, é‡‡é›†ä½ç½®ç‚¹æ•°)
        """
        total_tasks_processed = 0
        total_positions_collected = 0

        # éå†æ¯ä¸ªå«æ˜Ÿçš„å¯è§ä»»åŠ¡
        for satellite_id, satellite_tasks in constellation_visible_task_sets.items():
            logger.info(f"ğŸ›°ï¸ å¤„ç†å«æ˜Ÿ {satellite_id} çš„å¯è§ä»»åŠ¡...")

            # å¤„ç†è¯¥å«æ˜Ÿçš„æ‰€æœ‰å¯¼å¼¹ä»»åŠ¡
            missile_tasks = satellite_tasks.get("missile_tasks", {})

            for missile_id, missile_task_data in missile_tasks.items():
                # å¤„ç†å¯è§ä»»åŠ¡
                visible_tasks = missile_task_data.get("visible_tasks", [])

                for task in visible_tasks:
                    # ä¸ºæ¯ä¸ªå¯è§ä»»åŠ¡åŒæ­¥å«æ˜Ÿä½ç½®
                    position_data = self._synchronize_position_for_task(
                        satellite_id, task
                    )

                    if position_data:
                        task["satellite_position_sync"] = position_data
                        total_positions_collected += len(position_data.get("position_samples", []))
                        total_tasks_processed += 1

                        logger.debug(f"âœ… ä»»åŠ¡ {task.get('task_id')} ä½ç½®åŒæ­¥å®Œæˆ")
                    else:
                        logger.warning(f"âš ï¸ ä»»åŠ¡ {task.get('task_id')} ä½ç½®åŒæ­¥å¤±è´¥")

        return total_tasks_processed, total_positions_collected

    def _synchronize_position_for_task_thread_safe(self, satellite_id: str, task: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        çº¿ç¨‹å®‰å…¨çš„ä»»åŠ¡ä½ç½®åŒæ­¥æ–¹æ³•

        Args:
            satellite_id: å«æ˜ŸID
            task: ä»»åŠ¡ä¿¡æ¯

        Returns:
            ä½ç½®åŒæ­¥æ•°æ®
        """
        try:
            # ä½¿ç”¨é”ç¡®ä¿STK COMæ¥å£çš„çº¿ç¨‹å®‰å…¨
            with self._stk_lock:
                return self._synchronize_position_for_task(satellite_id, task)
        except Exception as e:
            logger.error(f"âŒ çº¿ç¨‹å®‰å…¨ä½ç½®åŒæ­¥å¤±è´¥ {task.get('task_id')}: {e}")
            return None

    def _synchronize_position_for_task(self, satellite_id: str, task: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        ä¸ºå•ä¸ªä»»åŠ¡åŒæ­¥å«æ˜Ÿä½ç½®
        
        Args:
            satellite_id: å«æ˜ŸID
            task: ä»»åŠ¡ä¿¡æ¯
            
        Returns:
            ä½ç½®åŒæ­¥æ•°æ®
        """
        try:
            # è·å–ä»»åŠ¡æ—¶é—´èŒƒå›´
            start_time_str = task.get("start_time_iso") or task.get("start_time")
            end_time_str = task.get("end_time_iso") or task.get("end_time")
            
            if not start_time_str or not end_time_str:
                logger.warning(f"âš ï¸ ä»»åŠ¡æ—¶é—´ä¿¡æ¯ä¸å®Œæ•´: {task.get('task_id')}")
                return None
            
            # è§£ææ—¶é—´
            start_time = self._parse_time_string(start_time_str)
            end_time = self._parse_time_string(end_time_str)
            
            if not start_time or not end_time:
                logger.warning(f"âš ï¸ ä»»åŠ¡æ—¶é—´è§£æå¤±è´¥: {task.get('task_id')}")
                return None
            
            # è®¡ç®—é‡‡æ ·æ—¶é—´ç‚¹
            sample_times = self._calculate_sample_times(start_time, end_time)
            
            # é‡‡é›†ä½ç½®æ•°æ®
            position_samples = []
            
            for sample_time in sample_times:
                # è®¡ç®—ç›¸å¯¹äºåœºæ™¯å¼€å§‹æ—¶é—´çš„åç§»
                time_offset = self._calculate_time_offset(sample_time)
                
                # è·å–å«æ˜Ÿåœ¨è¯¥æ—¶é—´ç‚¹çš„ä½ç½®ï¼ˆä½¿ç”¨é…ç½®çš„è¶…æ—¶æ—¶é—´ï¼‰
                position_data = self.stk_manager.get_satellite_position(satellite_id, time_offset, self.stk_com_timeout)
                
                if position_data:
                    # å¢å¼ºä½ç½®æ•°æ®
                    enhanced_position = {
                        "sample_time": sample_time.isoformat(),
                        "time_offset_seconds": time_offset,
                        "position": position_data,
                        "task_relative_time": (sample_time - start_time).total_seconds()
                    }
                    position_samples.append(enhanced_position)
                else:
                    logger.debug(f"âš ï¸ æ— æ³•è·å– {satellite_id} åœ¨ {sample_time} çš„ä½ç½®")
            
            if not position_samples:
                logger.warning(f"âš ï¸ ä»»åŠ¡ {task.get('task_id')} æœªè·å–åˆ°ä»»ä½•ä½ç½®æ•°æ®")
                return None
            
            # è®¡ç®—ä½ç½®ç»Ÿè®¡ä¿¡æ¯
            position_stats = self._calculate_position_statistics(position_samples)
            
            return {
                "task_id": task.get("task_id"),
                "satellite_id": satellite_id,
                "task_time_range": {
                    "start_time": start_time.isoformat(),
                    "end_time": end_time.isoformat(),
                    "duration_seconds": (end_time - start_time).total_seconds()
                },
                "position_samples": position_samples,
                "position_statistics": position_stats,
                "sample_count": len(position_samples),
                "sample_interval_seconds": self.position_sample_interval
            }
            
        except Exception as e:
            logger.error(f"âŒ ä»»åŠ¡ä½ç½®åŒæ­¥å¤±è´¥ {task.get('task_id')}: {e}")
            return None
    
    def _parse_time_string(self, time_str: str) -> Optional[datetime]:
        """è§£ææ—¶é—´å­—ç¬¦ä¸²"""
        try:
            # å°è¯•ISOæ ¼å¼
            if 'T' in time_str:
                return datetime.fromisoformat(time_str.replace('T', ' '))
            else:
                return datetime.fromisoformat(time_str)
        except:
            try:
                # å°è¯•æ ‡å‡†æ ¼å¼
                return datetime.strptime(time_str, "%Y-%m-%d %H:%M:%S")
            except:
                logger.warning(f"âš ï¸ æ— æ³•è§£ææ—¶é—´å­—ç¬¦ä¸²: {time_str}")
                return None
    
    def _calculate_sample_times(self, start_time: datetime, end_time: datetime) -> List[datetime]:
        """è®¡ç®—é‡‡æ ·æ—¶é—´ç‚¹"""
        sample_times = []

        # ä»»åŠ¡æŒç»­æ—¶é—´
        duration = (end_time - start_time).total_seconds()

        # ğŸ”§ ä¿®å¤ï¼šæ”¹è¿›çŸ­ä»»åŠ¡çš„åˆ¤æ–­é€»è¾‘
        if duration <= self.position_sample_interval * 2:
            # çŸ­ä»»åŠ¡ï¼šåªé‡‡æ ·å¼€å§‹å’Œç»“æŸæ—¶é—´
            sample_times = [start_time]
            if start_time != end_time:
                sample_times.append(end_time)
        else:
            # é•¿ä»»åŠ¡ï¼šæŒ‰é—´éš”é‡‡æ ·
            current_time = start_time
            while current_time <= end_time:
                sample_times.append(current_time)
                current_time += timedelta(seconds=self.position_sample_interval)

            # ç¡®ä¿åŒ…å«ç»“æŸæ—¶é—´
            if sample_times[-1] != end_time:
                sample_times.append(end_time)

        # é™åˆ¶æœ€å¤§é‡‡æ ·ç‚¹æ•°
        if len(sample_times) > self.max_samples_per_task:
            # å‡åŒ€åˆ†å¸ƒé‡‡æ ·ç‚¹
            step = max(1, len(sample_times) // self.max_samples_per_task)
            sample_times = sample_times[::step][:self.max_samples_per_task]

            # ç¡®ä¿åŒ…å«å¼€å§‹å’Œç»“æŸæ—¶é—´
            if start_time not in sample_times:
                sample_times[0] = start_time
            if end_time not in sample_times and len(sample_times) > 1:
                sample_times[-1] = end_time

        return sample_times
    
    def _calculate_time_offset(self, target_time: datetime) -> float:
        """è®¡ç®—ç›¸å¯¹äºåœºæ™¯å¼€å§‹æ—¶é—´çš„åç§»é‡ï¼ˆç§’ï¼‰"""
        try:
            scenario_start = self.time_manager.start_time
            offset = (target_time - scenario_start).total_seconds()
            return offset
        except Exception as e:
            logger.warning(f"âš ï¸ æ—¶é—´åç§»è®¡ç®—å¤±è´¥: {e}")
            return 0.0
    
    def _calculate_position_statistics(self, position_samples: List[Dict[str, Any]]) -> Dict[str, Any]:
        """è®¡ç®—ä½ç½®ç»Ÿè®¡ä¿¡æ¯"""
        try:
            if not position_samples:
                return {}
            
            # æå–åæ ‡æ•°æ®
            coordinates = []
            for sample in position_samples:
                pos = sample.get("position", {})
                if "x" in pos and "y" in pos and "z" in pos:
                    coordinates.append((pos["x"], pos["y"], pos["z"]))
                elif "lat" in pos and "lon" in pos and "alt" in pos:
                    coordinates.append((pos["lat"], pos["lon"], pos["alt"]))
            
            if not coordinates:
                return {"error": "no_valid_coordinates"}
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            if len(coordinates[0]) == 3:  # ç¬›å¡å°”åæ ‡æˆ–LLAåæ ‡
                x_coords, y_coords, z_coords = zip(*coordinates)
                
                stats = {
                    "coordinate_type": "cartesian" if abs(max(x_coords)) > 1000 else "lla",
                    "x_range": {"min": min(x_coords), "max": max(x_coords)},
                    "y_range": {"min": min(y_coords), "max": max(y_coords)},
                    "z_range": {"min": min(z_coords), "max": max(z_coords)},
                    "sample_count": len(coordinates)
                }
                
                # è®¡ç®—ç§»åŠ¨è·ç¦»ï¼ˆå¦‚æœæ˜¯ç¬›å¡å°”åæ ‡ï¼‰
                if stats["coordinate_type"] == "cartesian":
                    total_distance = 0
                    for i in range(1, len(coordinates)):
                        dx = coordinates[i][0] - coordinates[i-1][0]
                        dy = coordinates[i][1] - coordinates[i-1][1]
                        dz = coordinates[i][2] - coordinates[i-1][2]
                        distance = (dx**2 + dy**2 + dz**2)**0.5
                        total_distance += distance
                    
                    stats["total_movement_km"] = total_distance / 1000  # è½¬æ¢ä¸ºå…¬é‡Œ
                
                return stats
            
        except Exception as e:
            logger.warning(f"âš ï¸ ä½ç½®ç»Ÿè®¡è®¡ç®—å¤±è´¥: {e}")
            return {"error": str(e)}
        
        return {}
    
    def export_position_sync_data(self, enhanced_visible_tasks: Dict[str, Any], output_file: str):
        """å¯¼å‡ºä½ç½®åŒæ­¥æ•°æ®åˆ°æ–‡ä»¶"""
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(enhanced_visible_tasks, f, indent=2, ensure_ascii=False, default=str)
            
            logger.info(f"ğŸ“ ä½ç½®åŒæ­¥æ•°æ®å·²å¯¼å‡º: {output_file}")
            
        except Exception as e:
            logger.error(f"âŒ å¯¼å‡ºä½ç½®åŒæ­¥æ•°æ®å¤±è´¥: {e}")
