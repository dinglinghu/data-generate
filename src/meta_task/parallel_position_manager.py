#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¹¶è¡Œå«æ˜Ÿä½ç½®ç®¡ç†å™¨
ä½¿ç”¨å¤šç§å¹¶è¡Œç­–ç•¥ä¼˜åŒ–å«æ˜Ÿä½ç½®è·å–æ€§èƒ½
"""

import logging
import asyncio
import threading
import time
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple, Callable
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
from dataclasses import dataclass
from queue import Queue
import multiprocessing as mp

logger = logging.getLogger(__name__)

@dataclass
class PositionRequest:
    """ä½ç½®è¯·æ±‚æ•°æ®ç»“æ„"""
    satellite_id: str
    time_offset: float
    sample_time: datetime
    task_id: str = None
    priority: int = 1  # 1=é«˜ä¼˜å…ˆçº§, 2=ä¸­ä¼˜å…ˆçº§, 3=ä½ä¼˜å…ˆçº§

@dataclass
class PositionResult:
    """ä½ç½®ç»“æœæ•°æ®ç»“æ„"""
    request: PositionRequest
    position_data: Optional[Dict[str, Any]]
    success: bool
    error: Optional[str] = None
    processing_time: float = 0.0

class ParallelPositionManager:
    """å¹¶è¡Œå«æ˜Ÿä½ç½®ç®¡ç†å™¨"""
    
    def __init__(self, stk_manager, config_manager=None):
        """
        åˆå§‹åŒ–å¹¶è¡Œä½ç½®ç®¡ç†å™¨
        
        Args:
            stk_manager: STKç®¡ç†å™¨å®ä¾‹
            config_manager: é…ç½®ç®¡ç†å™¨å®ä¾‹
        """
        self.stk_manager = stk_manager
        self.config_manager = config_manager
        
        # å¹¶è¡Œé…ç½®
        self.max_workers = min(8, mp.cpu_count())  # æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°
        self.batch_size = 20  # æ‰¹å¤„ç†å¤§å°
        self.timeout_per_request = 10.0  # å•ä¸ªè¯·æ±‚è¶…æ—¶æ—¶é—´
        self.enable_async = True  # å¯ç”¨å¼‚æ­¥å¤„ç†
        self.enable_threading = True  # å¯ç”¨å¤šçº¿ç¨‹
        self.enable_batching = True  # å¯ç”¨æ‰¹å¤„ç†
        
        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "total_time": 0.0,
            "parallel_time": 0.0,
            "cache_hits": 0,
            "batch_count": 0
        }
        
        # ä½ç½®ç¼“å­˜
        self._position_cache = {}
        self._cache_lock = threading.Lock()
        
        logger.info(f"ğŸš€ å¹¶è¡Œä½ç½®ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   æœ€å¤§å·¥ä½œçº¿ç¨‹: {self.max_workers}")
        logger.info(f"   æ‰¹å¤„ç†å¤§å°: {self.batch_size}")
    
    def get_positions_parallel(self, requests: List[PositionRequest]) -> List[PositionResult]:
        """
        å¹¶è¡Œè·å–å¤šä¸ªå«æ˜Ÿä½ç½®
        
        Args:
            requests: ä½ç½®è¯·æ±‚åˆ—è¡¨
            
        Returns:
            ä½ç½®ç»“æœåˆ—è¡¨
        """
        if not requests:
            return []
        
        start_time = time.time()
        logger.info(f"ğŸš€ å¼€å§‹å¹¶è¡Œè·å– {len(requests)} ä¸ªä½ç½®...")
        
        # é€‰æ‹©æœ€ä¼˜çš„å¹¶è¡Œç­–ç•¥
        if self.enable_async and len(requests) > 10:
            results = self._get_positions_async(requests)
        elif self.enable_threading and len(requests) > 5:
            results = self._get_positions_threaded(requests)
        else:
            results = self._get_positions_serial(requests)
        
        total_time = time.time() - start_time
        
        # æ›´æ–°ç»Ÿè®¡
        self.stats["total_requests"] += len(requests)
        self.stats["successful_requests"] += sum(1 for r in results if r.success)
        self.stats["failed_requests"] += sum(1 for r in results if not r.success)
        self.stats["parallel_time"] += total_time
        
        success_rate = self.stats["successful_requests"] / self.stats["total_requests"] * 100
        
        logger.info(f"âœ… å¹¶è¡Œä½ç½®è·å–å®Œæˆ")
        logger.info(f"   å¤„ç†æ—¶é—´: {total_time:.2f}s")
        logger.info(f"   æˆåŠŸç‡: {success_rate:.1f}%")
        logger.info(f"   å¹³å‡æ¯ä¸ª: {total_time/len(requests):.3f}s")
        
        return results
    
    def _get_positions_async(self, requests: List[PositionRequest]) -> List[PositionResult]:
        """å¼‚æ­¥å¹¶è¡Œè·å–ä½ç½®"""
        logger.info(f"ğŸ”„ ä½¿ç”¨å¼‚æ­¥å¹¶è¡Œæ¨¡å¼å¤„ç† {len(requests)} ä¸ªè¯·æ±‚...")
        
        try:
            # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯ï¼ˆé¿å…ä¸ç°æœ‰å¾ªç¯å†²çªï¼‰
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            
            try:
                results = loop.run_until_complete(self._async_get_positions(requests))
                return results
            finally:
                loop.close()
                
        except Exception as e:
            logger.error(f"âŒ å¼‚æ­¥å¤„ç†å¤±è´¥ï¼Œå›é€€åˆ°çº¿ç¨‹æ¨¡å¼: {e}")
            return self._get_positions_threaded(requests)
    
    async def _async_get_positions(self, requests: List[PositionRequest]) -> List[PositionResult]:
        """å¼‚æ­¥è·å–ä½ç½®çš„æ ¸å¿ƒå®ç°"""
        semaphore = asyncio.Semaphore(self.max_workers)
        
        async def get_single_position(request: PositionRequest) -> PositionResult:
            async with semaphore:
                return await self._async_single_position(request)
        
        # åˆ›å»ºæ‰€æœ‰ä»»åŠ¡
        tasks = [get_single_position(req) for req in requests]
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†å¼‚å¸¸ç»“æœ
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                processed_results.append(PositionResult(
                    request=requests[i],
                    position_data=None,
                    success=False,
                    error=str(result)
                ))
            else:
                processed_results.append(result)
        
        return processed_results
    
    async def _async_single_position(self, request: PositionRequest) -> PositionResult:
        """å¼‚æ­¥è·å–å•ä¸ªä½ç½®"""
        start_time = time.time()
        
        try:
            # æ£€æŸ¥ç¼“å­˜
            cache_key = f"{request.satellite_id}_{request.time_offset}"
            cached_result = self._get_cached_position(cache_key)
            if cached_result:
                self.stats["cache_hits"] += 1
                return PositionResult(
                    request=request,
                    position_data=cached_result,
                    success=True,
                    processing_time=time.time() - start_time
                )
            
            # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒSTKè°ƒç”¨ï¼ˆé¿å…é˜»å¡äº‹ä»¶å¾ªç¯ï¼‰
            loop = asyncio.get_event_loop()
            position_data = await loop.run_in_executor(
                None,
                self._get_position_sync,
                request.satellite_id,
                request.time_offset
            )
            
            # ç¼“å­˜ç»“æœ
            if position_data:
                self._cache_position(cache_key, position_data)
            
            return PositionResult(
                request=request,
                position_data=position_data,
                success=position_data is not None,
                processing_time=time.time() - start_time
            )
            
        except Exception as e:
            return PositionResult(
                request=request,
                position_data=None,
                success=False,
                error=str(e),
                processing_time=time.time() - start_time
            )
    
    def _get_positions_threaded(self, requests: List[PositionRequest]) -> List[PositionResult]:
        """å¤šçº¿ç¨‹å¹¶è¡Œè·å–ä½ç½®"""
        logger.info(f"ğŸ§µ ä½¿ç”¨å¤šçº¿ç¨‹æ¨¡å¼å¤„ç† {len(requests)} ä¸ªè¯·æ±‚...")
        
        results = []
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_request = {
                executor.submit(self._get_single_position_threaded, req): req 
                for req in requests
            }
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_request, timeout=self.timeout_per_request * len(requests)):
                try:
                    result = future.result(timeout=self.timeout_per_request)
                    results.append(result)
                except Exception as e:
                    request = future_to_request[future]
                    results.append(PositionResult(
                        request=request,
                        position_data=None,
                        success=False,
                        error=str(e)
                    ))
        
        return results
    
    def _get_single_position_threaded(self, request: PositionRequest) -> PositionResult:
        """çº¿ç¨‹å®‰å…¨çš„å•ä¸ªä½ç½®è·å–"""
        start_time = time.time()
        
        try:
            # æ£€æŸ¥ç¼“å­˜
            cache_key = f"{request.satellite_id}_{request.time_offset}"
            cached_result = self._get_cached_position(cache_key)
            if cached_result:
                self.stats["cache_hits"] += 1
                return PositionResult(
                    request=request,
                    position_data=cached_result,
                    success=True,
                    processing_time=time.time() - start_time
                )
            
            # è·å–ä½ç½®æ•°æ®
            position_data = self._get_position_sync(request.satellite_id, request.time_offset)
            
            # ç¼“å­˜ç»“æœ
            if position_data:
                self._cache_position(cache_key, position_data)
            
            return PositionResult(
                request=request,
                position_data=position_data,
                success=position_data is not None,
                processing_time=time.time() - start_time
            )
            
        except Exception as e:
            return PositionResult(
                request=request,
                position_data=None,
                success=False,
                error=str(e),
                processing_time=time.time() - start_time
            )
    
    def _get_positions_serial(self, requests: List[PositionRequest]) -> List[PositionResult]:
        """ä¸²è¡Œè·å–ä½ç½®ï¼ˆå›é€€æ–¹æ¡ˆï¼‰"""
        logger.info(f"ğŸ“ ä½¿ç”¨ä¸²è¡Œæ¨¡å¼å¤„ç† {len(requests)} ä¸ªè¯·æ±‚...")
        
        results = []
        for request in requests:
            result = self._get_single_position_threaded(request)
            results.append(result)
        
        return results
    
    def _get_position_sync(self, satellite_id: str, time_offset: float) -> Optional[Dict[str, Any]]:
        """åŒæ­¥è·å–ä½ç½®æ•°æ®ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        try:
            # è°ƒç”¨STKç®¡ç†å™¨è·å–ä½ç½®
            position_data = self.stk_manager.get_satellite_position(
                satellite_id, 
                str(time_offset), 
                timeout=self.timeout_per_request
            )
            return position_data
        except Exception as e:
            logger.debug(f"ä½ç½®è·å–å¤±è´¥ {satellite_id}: {e}")
            return None
    
    def _get_cached_position(self, cache_key: str) -> Optional[Dict[str, Any]]:
        """çº¿ç¨‹å®‰å…¨çš„ç¼“å­˜è·å–"""
        with self._cache_lock:
            return self._position_cache.get(cache_key)
    
    def _cache_position(self, cache_key: str, position_data: Dict[str, Any]):
        """çº¿ç¨‹å®‰å…¨çš„ç¼“å­˜å­˜å‚¨"""
        with self._cache_lock:
            self._position_cache[cache_key] = position_data
    
    def clear_cache(self):
        """æ¸…ç©ºä½ç½®ç¼“å­˜"""
        with self._cache_lock:
            self._position_cache.clear()
        logger.info("ğŸ§¹ ä½ç½®ç¼“å­˜å·²æ¸…ç©º")
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        stats = self.stats.copy()
        
        if stats["total_requests"] > 0:
            stats["success_rate"] = stats["successful_requests"] / stats["total_requests"] * 100
            stats["average_time_per_request"] = stats["parallel_time"] / stats["total_requests"]
        else:
            stats["success_rate"] = 0.0
            stats["average_time_per_request"] = 0.0
        
        stats["cache_hit_rate"] = (stats["cache_hits"] / stats["total_requests"] * 100) if stats["total_requests"] > 0 else 0.0
        stats["cache_size"] = len(self._position_cache)
        
        return stats
    
    def reset_stats(self):
        """é‡ç½®æ€§èƒ½ç»Ÿè®¡"""
        self.stats = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "total_time": 0.0,
            "parallel_time": 0.0,
            "cache_hits": 0,
            "batch_count": 0
        }
