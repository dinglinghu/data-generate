#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¹¶è¡Œå«æ˜Ÿä½ç½®ç®¡ç†å™¨
ä½¿ç”¨å¤šç§å¹¶è¡Œç­–ç•¥ä¼˜åŒ–å«æ˜Ÿä½ç½®è·å–æ€§èƒ½
"""

import logging
import asyncio
import threading
import time
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple, Callable
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
from dataclasses import dataclass
from queue import Queue
import multiprocessing as mp

logger = logging.getLogger(__name__)

@dataclass
class PositionRequest:
    """ä½ç½®è¯·æ±‚æ•°æ®ç»“æ„"""
    satellite_id: str
    time_offset: float
    sample_time: datetime
    task_id: str = None
    priority: int = 1  # 1=é«˜ä¼˜å…ˆçº§, 2=ä¸­ä¼˜å…ˆçº§, 3=ä½ä¼˜å…ˆçº§

@dataclass
class PositionResult:
    """ä½ç½®ç»“æœæ•°æ®ç»“æ„"""
    request: PositionRequest
    position_data: Optional[Dict[str, Any]]
    success: bool
    error: Optional[str] = None
    processing_time: float = 0.0

class ParallelPositionManager:
    """å¹¶è¡Œå«æ˜Ÿä½ç½®ç®¡ç†å™¨"""
    
    def __init__(self, stk_manager, config_manager=None):
        """
        åˆå§‹åŒ–å¹¶è¡Œä½ç½®ç®¡ç†å™¨
        
        Args:
            stk_manager: STKç®¡ç†å™¨å®ä¾‹
            config_manager: é…ç½®ç®¡ç†å™¨å®ä¾‹
        """
        self.stk_manager = stk_manager
        self.config_manager = config_manager
        
        # å¹¶è¡Œé…ç½®
        self.max_workers = min(8, mp.cpu_count())  # æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°
        self.batch_size = 20  # æ‰¹å¤„ç†å¤§å°
        self.timeout_per_request = 10.0  # å•ä¸ªè¯·æ±‚è¶…æ—¶æ—¶é—´
        self.enable_async = True  # å¯ç”¨å¼‚æ­¥å¤„ç†
        self.enable_threading = True  # å¯ç”¨å¤šçº¿ç¨‹
        self.enable_batching = True  # å¯ç”¨æ‰¹å¤„ç†

        # ç¼“å­˜é…ç½® - ä»é…ç½®æ–‡ä»¶è¯»å–
        if config_manager:
            position_config = config_manager.get_position_config()
            self.enable_cache = position_config.get('enable_position_cache', False)
        else:
            self.enable_cache = False  # é»˜è®¤ç¦ç”¨ç¼“å­˜

        logger.info(f"ğŸ’¾ ä½ç½®ç¼“å­˜: {'å¯ç”¨' if self.enable_cache else 'ç¦ç”¨'}")
        
        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "total_time": 0.0,
            "parallel_time": 0.0,
            "cache_hits": 0,
            "batch_count": 0
        }
        
        # ä½ç½®ç¼“å­˜
        self._position_cache = {}
        self._cache_lock = threading.Lock()
        
        logger.info(f"ğŸš€ å¹¶è¡Œä½ç½®ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   æœ€å¤§å·¥ä½œçº¿ç¨‹: {self.max_workers}")
        logger.info(f"   æ‰¹å¤„ç†å¤§å°: {self.batch_size}")
    
    def get_positions_parallel(self, requests: List[PositionRequest]) -> List[PositionResult]:
        """
        å¹¶è¡Œè·å–å¤šä¸ªå«æ˜Ÿä½ç½®
        
        Args:
            requests: ä½ç½®è¯·æ±‚åˆ—è¡¨
            
        Returns:
            ä½ç½®ç»“æœåˆ—è¡¨
        """
        if not requests:
            return []
        
        start_time = time.time()
        logger.info(f"ğŸš€ å¼€å§‹å¹¶è¡Œè·å– {len(requests)} ä¸ªä½ç½®...")
        
        # ä¸´æ—¶ç¦ç”¨å¤šçº¿ç¨‹æ¨¡å¼ï¼Œé¿å…STK COMå¯¹è±¡çš„å¤šçº¿ç¨‹é—®é¢˜
        # å¼ºåˆ¶ä½¿ç”¨ä¸²è¡Œæ¨¡å¼
        logger.info("ğŸ”§ ä½¿ç”¨ä¸²è¡Œæ¨¡å¼é¿å…STK COMå¤šçº¿ç¨‹é—®é¢˜")
        results = self._get_positions_serial(requests)
        
        total_time = time.time() - start_time
        
        # æ›´æ–°ç»Ÿè®¡
        self.stats["total_requests"] += len(requests)
        self.stats["successful_requests"] += sum(1 for r in results if r.success)
        self.stats["failed_requests"] += sum(1 for r in results if not r.success)
        self.stats["parallel_time"] += total_time
        
        success_rate = self.stats["successful_requests"] / self.stats["total_requests"] * 100
        
        logger.info(f"âœ… å¹¶è¡Œä½ç½®è·å–å®Œæˆ")
        logger.info(f"   å¤„ç†æ—¶é—´: {total_time:.2f}s")
        logger.info(f"   æˆåŠŸç‡: {success_rate:.1f}%")
        logger.info(f"   å¹³å‡æ¯ä¸ª: {total_time/len(requests):.3f}s")
        
        return results
    
    def _get_positions_async(self, requests: List[PositionRequest]) -> List[PositionResult]:
        """å¼‚æ­¥å¹¶è¡Œè·å–ä½ç½®"""
        logger.info(f"ğŸ”„ ä½¿ç”¨å¼‚æ­¥å¹¶è¡Œæ¨¡å¼å¤„ç† {len(requests)} ä¸ªè¯·æ±‚...")
        
        try:
            # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯ï¼ˆé¿å…ä¸ç°æœ‰å¾ªç¯å†²çªï¼‰
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            
            try:
                results = loop.run_until_complete(self._async_get_positions(requests))
                return results
            finally:
                loop.close()
                
        except Exception as e:
            logger.error(f"âŒ å¼‚æ­¥å¤„ç†å¤±è´¥ï¼Œå›é€€åˆ°çº¿ç¨‹æ¨¡å¼: {e}")
            return self._get_positions_threaded(requests)
    
    async def _async_get_positions(self, requests: List[PositionRequest]) -> List[PositionResult]:
        """å¼‚æ­¥è·å–ä½ç½®çš„æ ¸å¿ƒå®ç°"""
        semaphore = asyncio.Semaphore(self.max_workers)
        
        async def get_single_position(request: PositionRequest) -> PositionResult:
            async with semaphore:
                return await self._async_single_position(request)
        
        # åˆ›å»ºæ‰€æœ‰ä»»åŠ¡
        tasks = [get_single_position(req) for req in requests]
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†å¼‚å¸¸ç»“æœ
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                processed_results.append(PositionResult(
                    request=requests[i],
                    position_data=None,
                    success=False,
                    error=str(result)
                ))
            else:
                processed_results.append(result)
        
        return processed_results
    
    async def _async_single_position(self, request: PositionRequest) -> PositionResult:
        """å¼‚æ­¥è·å–å•ä¸ªä½ç½®"""
        start_time = time.time()
        
        try:
            # æ£€æŸ¥ç¼“å­˜
            cache_key = f"{request.satellite_id}_{request.time_offset}"
            cached_result = self._get_cached_position(cache_key)
            if cached_result:
                self.stats["cache_hits"] += 1
                return PositionResult(
                    request=request,
                    position_data=cached_result,
                    success=True,
                    processing_time=time.time() - start_time
                )
            
            # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒSTKè°ƒç”¨ï¼ˆé¿å…é˜»å¡äº‹ä»¶å¾ªç¯ï¼‰
            loop = asyncio.get_event_loop()
            position_data = await loop.run_in_executor(
                None,
                self._get_position_sync,
                request.satellite_id,
                request.time_offset
            )
            
            # ç¼“å­˜ç»“æœ
            if position_data:
                self._cache_position(cache_key, position_data)
            
            return PositionResult(
                request=request,
                position_data=position_data,
                success=position_data is not None,
                processing_time=time.time() - start_time
            )
            
        except Exception as e:
            return PositionResult(
                request=request,
                position_data=None,
                success=False,
                error=str(e),
                processing_time=time.time() - start_time
            )
    
    def _get_positions_threaded(self, requests: List[PositionRequest]) -> List[PositionResult]:
        """å¤šçº¿ç¨‹å¹¶è¡Œè·å–ä½ç½®"""
        logger.info(f"ğŸ§µ ä½¿ç”¨å¤šçº¿ç¨‹æ¨¡å¼å¤„ç† {len(requests)} ä¸ªè¯·æ±‚...")
        
        results = []
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_request = {
                executor.submit(self._get_single_position_threaded, req): req 
                for req in requests
            }
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_request, timeout=self.timeout_per_request * len(requests)):
                try:
                    result = future.result(timeout=self.timeout_per_request)
                    results.append(result)
                except Exception as e:
                    request = future_to_request[future]
                    results.append(PositionResult(
                        request=request,
                        position_data=None,
                        success=False,
                        error=str(e)
                    ))
        
        return results
    
    def _get_single_position_threaded(self, request: PositionRequest) -> PositionResult:
        """çº¿ç¨‹å®‰å…¨çš„å•ä¸ªä½ç½®è·å–"""
        start_time = time.time()
        
        try:
            # æ£€æŸ¥ç¼“å­˜
            cache_key = f"{request.satellite_id}_{request.time_offset}"
            cached_result = self._get_cached_position(cache_key)
            if cached_result:
                self.stats["cache_hits"] += 1
                return PositionResult(
                    request=request,
                    position_data=cached_result,
                    success=True,
                    processing_time=time.time() - start_time
                )
            
            # è·å–ä½ç½®æ•°æ®
            position_data = self._get_position_sync(request.satellite_id, request.time_offset)
            
            # ç¼“å­˜ç»“æœ
            if position_data:
                self._cache_position(cache_key, position_data)
            
            return PositionResult(
                request=request,
                position_data=position_data,
                success=position_data is not None,
                processing_time=time.time() - start_time
            )
            
        except Exception as e:
            return PositionResult(
                request=request,
                position_data=None,
                success=False,
                error=str(e),
                processing_time=time.time() - start_time
            )
    
    def _get_positions_serial(self, requests: List[PositionRequest]) -> List[PositionResult]:
        """ä¸²è¡Œè·å–ä½ç½®ï¼ˆå›é€€æ–¹æ¡ˆï¼‰"""
        logger.info(f"ğŸ“ ä½¿ç”¨ä¸²è¡Œæ¨¡å¼å¤„ç† {len(requests)} ä¸ªè¯·æ±‚...")

        results = []
        for i, request in enumerate(requests):
            start_time = time.time()
            logger.info(f"ğŸ“ å¤„ç†ä½ç½®è¯·æ±‚ {i+1}/{len(requests)}: {request.satellite_id} @ {request.time_offset}s")

            try:
                logger.info(f"ğŸ” å¼€å§‹å¤„ç†è¯·æ±‚: {request.satellite_id} @ {request.time_offset}s")

                # æ£€æŸ¥ç¼“å­˜ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                cache_key = f"{request.satellite_id}_{request.time_offset}"
                logger.info(f"ğŸ” æ£€æŸ¥ç¼“å­˜: {cache_key}")
                cached_result = self._get_cached_position(cache_key)
                if cached_result:
                    self.stats["cache_hits"] += 1
                    logger.info(f"ğŸ’¾ ä½¿ç”¨ç¼“å­˜æ•°æ®: {request.satellite_id}")
                    results.append(PositionResult(
                        request=request,
                        position_data=cached_result,
                        success=True,
                        processing_time=time.time() - start_time
                    ))
                    continue

                logger.info(f"ğŸ” ä»STKè·å–å®æ—¶ä½ç½®: {request.satellite_id}")
                # ä½¿ç”¨åŸå§‹STKç®¡ç†å™¨æ–¹æ³•è·å–ä½ç½®
                position_data = self.stk_manager.get_satellite_position(
                    request.satellite_id,
                    str(request.time_offset),
                    timeout=self.timeout_per_request
                )
                logger.info(f"ğŸ” STKä½ç½®è·å–å®Œæˆ: {request.satellite_id}, ç»“æœ: {position_data is not None}")

                # ç¼“å­˜ç»“æœï¼ˆå¦‚æœå¯ç”¨ä¸”è·å–æˆåŠŸï¼‰
                if position_data and self.enable_cache:
                    self._cache_position(cache_key, position_data)
                    logger.info(f"ğŸ’¾ ä½ç½®æ•°æ®å·²ç¼“å­˜: {request.satellite_id}")

                success = position_data is not None
                processing_time = time.time() - start_time

                if success:
                    logger.info(f"âœ… ä½ç½®è·å–æˆåŠŸ: {request.satellite_id} (è€—æ—¶: {processing_time:.3f}s)")
                else:
                    logger.error(f"âŒ ä½ç½®è·å–å¤±è´¥: {request.satellite_id} (è€—æ—¶: {processing_time:.3f}s)")

                results.append(PositionResult(
                    request=request,
                    position_data=position_data,
                    success=success,
                    processing_time=processing_time
                ))

            except Exception as e:
                logger.error(f"âŒ å¤„ç†è¯·æ±‚å¼‚å¸¸: {request.satellite_id} @ {request.time_offset}s - {e}")
                import traceback
                logger.error(f"âŒ å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
                results.append(PositionResult(
                    request=request,
                    position_data=None,
                    success=False,
                    error=str(e),
                    processing_time=time.time() - start_time
                ))

        return results
    
    def _get_position_sync(self, satellite_id: str, time_offset: float) -> Optional[Dict[str, Any]]:
        """åŒæ­¥è·å–ä½ç½®æ•°æ®ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        try:
            # åœ¨å¤šçº¿ç¨‹ç¯å¢ƒä¸­åˆå§‹åŒ–COM
            import pythoncom
            pythoncom.CoInitialize()

            try:
                # åœ¨æ¯ä¸ªçº¿ç¨‹ä¸­é‡æ–°è·å–STKåº”ç”¨ç¨‹åºå¯¹è±¡
                import win32com.client
                stk_app = win32com.client.Dispatch("STK12.Application")

                # è·å–å½“å‰åœºæ™¯
                scenario = stk_app.ActiveScenario
                if not scenario:
                    logger.warning(f"çº¿ç¨‹ä¸­æ— æ³•è·å–æ´»åŠ¨åœºæ™¯")
                    return None

                # æŸ¥æ‰¾å«æ˜Ÿ
                satellite = None
                target_name = satellite_id
                if satellite_id.startswith("Satellite/"):
                    target_name = satellite_id.split("/", 1)[1]

                for i in range(scenario.Children.Count):
                    child = scenario.Children.Item(i)
                    if (getattr(child, 'ClassName', None) == 'Satellite' and
                        getattr(child, 'InstanceName', None) == target_name):
                        satellite = child
                        break

                if not satellite:
                    logger.warning(f"çº¿ç¨‹ä¸­æœªæ‰¾åˆ°å«æ˜Ÿ: {satellite_id}")
                    return None

                # è®¡ç®—ç›®æ ‡æ—¶é—´
                from src.utils.time_manager import get_time_manager
                from datetime import timedelta
                time_manager = get_time_manager()
                target_time = time_manager.start_time + timedelta(seconds=float(time_offset))
                stk_time = target_time.strftime("%d %b %Y %H:%M:%S.000")

                # è·å–ä½ç½®æ•°æ®
                try:
                    dp = satellite.DataProviders.Item("Cartesian Position")
                    result = dp.Exec(stk_time, stk_time)

                    if result and result.DataSets.Count > 0:
                        dataset = result.DataSets.Item(0)
                        if dataset.RowCount > 0:
                            x = float(dataset.GetValue(0, 1))
                            y = float(dataset.GetValue(0, 2))
                            z = float(dataset.GetValue(0, 3))
                            return {
                                'time': stk_time,
                                'x': x,
                                'y': y,
                                'z': z
                            }
                except Exception as pos_e:
                    logger.debug(f"Cartesian Positionå¤±è´¥: {pos_e}")

                    # å°è¯•LLA Position
                    try:
                        dp = satellite.DataProviders.Item("LLA Position")
                        result = dp.Exec(stk_time, stk_time)

                        if result and result.DataSets.Count > 0:
                            dataset = result.DataSets.Item(0)
                            if dataset.RowCount > 0:
                                lat = float(dataset.GetValue(0, 1))
                                lon = float(dataset.GetValue(0, 2))
                                alt = float(dataset.GetValue(0, 3))
                                return {
                                    'time': stk_time,
                                    'latitude': lat,
                                    'longitude': lon,
                                    'altitude': alt
                                }
                    except Exception as lla_e:
                        logger.debug(f"LLA Positionå¤±è´¥: {lla_e}")

                return None

            finally:
                # æ¸…ç†COM
                pythoncom.CoUninitialize()

        except Exception as e:
            logger.warning(f"ä½ç½®è·å–å¤±è´¥ {satellite_id}: {e}")
            return None
    
    def _get_cached_position(self, cache_key: str) -> Optional[Dict[str, Any]]:
        """çº¿ç¨‹å®‰å…¨çš„ç¼“å­˜è·å–"""
        if not self.enable_cache:
            logger.debug(f"ğŸš« ç¼“å­˜å·²ç¦ç”¨ï¼Œè·³è¿‡ç¼“å­˜æŸ¥è¯¢: {cache_key}")
            return None

        with self._cache_lock:
            cached_data = self._position_cache.get(cache_key)
            if cached_data:
                logger.debug(f"ğŸ’¾ ç¼“å­˜å‘½ä¸­: {cache_key}")
            else:
                logger.debug(f"ğŸ’¾ ç¼“å­˜æœªå‘½ä¸­: {cache_key}")
            return cached_data

    def _cache_position(self, cache_key: str, position_data: Dict[str, Any]):
        """çº¿ç¨‹å®‰å…¨çš„ç¼“å­˜å­˜å‚¨"""
        if not self.enable_cache:
            logger.debug(f"ğŸš« ç¼“å­˜å·²ç¦ç”¨ï¼Œè·³è¿‡ç¼“å­˜å­˜å‚¨: {cache_key}")
            return

        with self._cache_lock:
            self._position_cache[cache_key] = position_data
            logger.debug(f"ğŸ’¾ æ•°æ®å·²ç¼“å­˜: {cache_key}")
    
    def clear_cache(self):
        """æ¸…ç©ºä½ç½®ç¼“å­˜"""
        with self._cache_lock:
            self._position_cache.clear()
        logger.info("ğŸ§¹ ä½ç½®ç¼“å­˜å·²æ¸…ç©º")
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        stats = self.stats.copy()
        
        if stats["total_requests"] > 0:
            stats["success_rate"] = stats["successful_requests"] / stats["total_requests"] * 100
            stats["average_time_per_request"] = stats["parallel_time"] / stats["total_requests"]
        else:
            stats["success_rate"] = 0.0
            stats["average_time_per_request"] = 0.0
        
        stats["cache_hit_rate"] = (stats["cache_hits"] / stats["total_requests"] * 100) if stats["total_requests"] > 0 else 0.0
        stats["cache_size"] = len(self._position_cache)
        
        return stats
    
    def reset_stats(self):
        """é‡ç½®æ€§èƒ½ç»Ÿè®¡"""
        self.stats = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "total_time": 0.0,
            "parallel_time": 0.0,
            "cache_hits": 0,
            "batch_count": 0
        }
