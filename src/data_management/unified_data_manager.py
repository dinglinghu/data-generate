#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€æ•°æ®ç®¡ç†å™¨
ç”¨äºç®¡ç†æ‰€æœ‰é‡‡é›†æ•°æ®çš„ç»Ÿä¸€ä¿å­˜ï¼Œæ”¯æŒJSONå’Œç”˜ç‰¹å›¾åˆ†æ–‡ä»¶å¤¹ä¿å­˜
"""

import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional

logger = logging.getLogger(__name__)


class UnifiedDataManager:
    """ç»Ÿä¸€æ•°æ®ç®¡ç†å™¨"""
    
    def __init__(self, config_manager=None):
        self.config_manager = config_manager
        self.session_data = []
        self.session_dir = None
        self.json_dir = None
        self.charts_dir = None
        
    def initialize_session(self, session_name: str = None) -> Path:
        """
        åˆå§‹åŒ–ä¼šè¯ï¼Œåˆ›å»ºç»Ÿä¸€çš„æ•°æ®ä¿å­˜ç›®å½•ç»“æ„
        
        Args:
            session_name: ä¼šè¯åç§°ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            ä¼šè¯ç›®å½•è·¯å¾„
        """
        try:
            # è·å–è¾“å‡ºé…ç½®
            if self.config_manager:
                output_config = self.config_manager.get_output_config()
                base_directory = output_config.get("base_directory", "output")
                file_naming = output_config.get("file_naming", {})
                session_prefix = file_naming.get("session_prefix", "session_")
            else:
                base_directory = "output"
                session_prefix = "session_"
            
            # åˆ›å»ºä¼šè¯ç›®å½•
            if session_name:
                session_dir_name = f"{session_prefix}{session_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            else:
                session_dir_name = f"{session_prefix}{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            self.session_dir = Path(base_directory) / "unified_collections" / session_dir_name
            
            # åˆ›å»ºç›®å½•ç»“æ„
            self.session_dir.mkdir(parents=True, exist_ok=True)
            
            # åˆ›å»ºåˆ†ç±»å­ç›®å½•
            self.json_dir = self.session_dir / "json_data"
            self.charts_dir = self.session_dir / "charts"
            logs_dir = self.session_dir / "logs"
            analysis_dir = self.session_dir / "analysis"
            
            self.json_dir.mkdir(exist_ok=True)
            self.charts_dir.mkdir(exist_ok=True)
            logs_dir.mkdir(exist_ok=True)
            analysis_dir.mkdir(exist_ok=True)
            
            logger.info(f"ğŸ“ ç»Ÿä¸€ä¼šè¯ç›®å½•å·²åˆ›å»º: {self.session_dir}")
            logger.info(f"   JSONæ•°æ®ç›®å½•: {self.json_dir}")
            logger.info(f"   å›¾è¡¨ç›®å½•: {self.charts_dir}")
            logger.info(f"   æ—¥å¿—ç›®å½•: {logs_dir}")
            logger.info(f"   åˆ†æç›®å½•: {analysis_dir}")
            
            return self.session_dir
            
        except Exception as e:
            logger.error(f"âŒ åˆå§‹åŒ–ä¼šè¯å¤±è´¥: {e}")
            raise
    
    def save_collection_data(self, collection_index: int, collection_result: Dict[str, Any], 
                           conflict_resolution_data: Optional[Dict[str, Any]] = None) -> Dict[str, str]:
        """
        ä¿å­˜å•æ¬¡é‡‡é›†çš„æ•°æ®åˆ°ç»Ÿä¸€ç›®å½•
        
        Args:
            collection_index: é‡‡é›†ç´¢å¼•
            collection_result: åŸå§‹é‡‡é›†æ•°æ®
            conflict_resolution_data: å†²çªæ¶ˆè§£æ•°æ®
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„å­—å…¸
        """
        try:
            if not self.session_dir:
                raise ValueError("ä¼šè¯æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨ initialize_session()")
            
            saved_files = {}
            
            # 1. ä¿å­˜åŸå§‹é‡‡é›†æ•°æ®
            original_file = self.json_dir / f"collection_{collection_index:03d}_original.json"
            with open(original_file, 'w', encoding='utf-8') as f:
                json.dump(collection_result, f, indent=2, ensure_ascii=False, default=str)
            saved_files['original_data'] = str(original_file)
            
            # 2. ä¿å­˜å†²çªæ¶ˆè§£æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
            if conflict_resolution_data:
                conflict_file = self.json_dir / f"collection_{collection_index:03d}_conflict_resolution.json"
                with open(conflict_file, 'w', encoding='utf-8') as f:
                    json.dump(conflict_resolution_data, f, indent=2, ensure_ascii=False, default=str)
                saved_files['conflict_resolution'] = str(conflict_file)
            
            # 3. ä¿å­˜æ—¶é—´è½´æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
            timeline_data = self._extract_timeline_data(collection_result)
            if timeline_data:
                timeline_file = self.json_dir / f"collection_{collection_index:03d}_timeline.json"
                with open(timeline_file, 'w', encoding='utf-8') as f:
                    json.dump(timeline_data, f, indent=2, ensure_ascii=False, default=str)
                saved_files['timeline_data'] = str(timeline_file)
            
            # 4. ä¿å­˜é‡‡é›†æ‘˜è¦
            summary_data = self._create_collection_summary(collection_index, collection_result, conflict_resolution_data)
            summary_file = self.json_dir / f"collection_{collection_index:03d}_summary.json"
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary_data, f, indent=2, ensure_ascii=False, default=str)
            saved_files['summary'] = str(summary_file)
            
            # 5. æ·»åŠ åˆ°ä¼šè¯æ•°æ®
            self.session_data.append({
                "collection_index": collection_index,
                "collection_time": collection_result.get("collection_time", ""),
                "files": saved_files,
                "statistics": summary_data.get("statistics", {})
            })
            
            logger.info(f"ğŸ’¾ ç¬¬ {collection_index} æ¬¡é‡‡é›†æ•°æ®å·²ä¿å­˜åˆ°ç»Ÿä¸€ç›®å½•")
            logger.info(f"   åŸå§‹æ•°æ®: {original_file.name}")
            if conflict_resolution_data:
                logger.info(f"   å†²çªæ¶ˆè§£æ•°æ®: {conflict_file.name}")
            
            return saved_files
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜é‡‡é›†æ•°æ®å¤±è´¥: {e}")
            return {}
    
    def save_gantt_chart(self, collection_index: int, chart_path: str, chart_type: str = "gantt") -> Optional[str]:
        """
        ä¿å­˜ç”˜ç‰¹å›¾åˆ°å›¾è¡¨ç›®å½•
        
        Args:
            collection_index: é‡‡é›†ç´¢å¼•
            chart_path: åŸå§‹å›¾è¡¨è·¯å¾„
            chart_type: å›¾è¡¨ç±»å‹
            
        Returns:
            æ–°çš„å›¾è¡¨è·¯å¾„
        """
        try:
            if not self.charts_dir:
                raise ValueError("ä¼šè¯æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨ initialize_session()")
            
            import shutil
            
            # ç¡®å®šæ–°çš„æ–‡ä»¶å
            chart_file = Path(chart_path)
            new_chart_name = f"collection_{collection_index:03d}_{chart_type}_{chart_file.name}"
            new_chart_path = self.charts_dir / new_chart_name
            
            # å¤åˆ¶å›¾è¡¨æ–‡ä»¶
            shutil.copy2(chart_path, new_chart_path)
            
            logger.info(f"ğŸ“ˆ ç¬¬ {collection_index} æ¬¡é‡‡é›†çš„{chart_type}å›¾è¡¨å·²ä¿å­˜: {new_chart_name}")
            
            return str(new_chart_path)
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜å›¾è¡¨å¤±è´¥: {e}")
            return None
    
    def generate_session_summary(self) -> Dict[str, Any]:
        """ç”Ÿæˆä¼šè¯æ±‡æ€»æ•°æ®"""
        try:
            if not self.session_data:
                logger.warning("âš ï¸ æ²¡æœ‰ä¼šè¯æ•°æ®å¯æ±‡æ€»")
                return {}
            
            # ç»Ÿè®¡ä¿¡æ¯
            total_collections = len(self.session_data)
            total_meta_tasks = sum(data.get("statistics", {}).get("total_meta_tasks", 0) for data in self.session_data)
            total_visible_tasks = sum(data.get("statistics", {}).get("total_visible_tasks", 0) for data in self.session_data)
            total_missiles = sum(data.get("statistics", {}).get("total_missiles", 0) for data in self.session_data)
            
            # æ—¶é—´èŒƒå›´
            collection_times = [data.get("collection_time", "") for data in self.session_data if data.get("collection_time")]
            start_time = min(collection_times) if collection_times else ""
            end_time = max(collection_times) if collection_times else ""
            
            session_summary = {
                "session_info": {
                    "session_dir": str(self.session_dir),
                    "total_collections": total_collections,
                    "start_time": start_time,
                    "end_time": end_time,
                    "created_at": datetime.now().isoformat()
                },
                "statistics": {
                    "total_meta_tasks": total_meta_tasks,
                    "total_visible_tasks": total_visible_tasks,
                    "total_missiles": total_missiles,
                    "average_meta_tasks_per_collection": total_meta_tasks / total_collections if total_collections > 0 else 0,
                    "average_visible_tasks_per_collection": total_visible_tasks / total_collections if total_collections > 0 else 0
                },
                "collections": self.session_data,
                "directory_structure": {
                    "json_data": str(self.json_dir),
                    "charts": str(self.charts_dir),
                    "logs": str(self.session_dir / "logs"),
                    "analysis": str(self.session_dir / "analysis")
                }
            }
            
            return session_summary
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆä¼šè¯æ±‡æ€»å¤±è´¥: {e}")
            return {}
    
    def save_session_summary(self) -> Optional[str]:
        """ä¿å­˜ä¼šè¯æ±‡æ€»åˆ°æ–‡ä»¶"""
        try:
            if not self.session_dir:
                raise ValueError("ä¼šè¯æœªåˆå§‹åŒ–")
            
            session_summary = self.generate_session_summary()
            if not session_summary:
                return None
            
            # ä¿å­˜JSONæ ¼å¼æ±‡æ€»
            summary_file = self.session_dir / "session_summary.json"
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(session_summary, f, indent=2, ensure_ascii=False, default=str)
            
            # ä¿å­˜å¯è¯»æ–‡æœ¬æ ¼å¼æ±‡æ€»
            text_summary_file = self.session_dir / "session_summary.txt"
            with open(text_summary_file, 'w', encoding='utf-8') as f:
                f.write("STKæ˜Ÿåº§é¢„è­¦å†²çªæ¶ˆè§£æ•°æ®é‡‡é›†ä¼šè¯æ±‡æ€»\n")
                f.write("=" * 60 + "\n\n")
                
                session_info = session_summary.get("session_info", {})
                f.write(f"ä¼šè¯ç›®å½•: {session_info.get('session_dir', '')}\n")
                f.write(f"æ€»é‡‡é›†æ¬¡æ•°: {session_info.get('total_collections', 0)}\n")
                f.write(f"å¼€å§‹æ—¶é—´: {session_info.get('start_time', '')}\n")
                f.write(f"ç»“æŸæ—¶é—´: {session_info.get('end_time', '')}\n\n")
                
                statistics = session_summary.get("statistics", {})
                f.write("ç»Ÿè®¡ä¿¡æ¯:\n")
                f.write(f"  æ€»å…ƒä»»åŠ¡æ•°: {statistics.get('total_meta_tasks', 0)}\n")
                f.write(f"  æ€»å¯è§ä»»åŠ¡æ•°: {statistics.get('total_visible_tasks', 0)}\n")
                f.write(f"  æ€»å¯¼å¼¹æ•°: {statistics.get('total_missiles', 0)}\n")
                f.write(f"  å¹³å‡æ¯æ¬¡é‡‡é›†å…ƒä»»åŠ¡æ•°: {statistics.get('average_meta_tasks_per_collection', 0):.2f}\n")
                f.write(f"  å¹³å‡æ¯æ¬¡é‡‡é›†å¯è§ä»»åŠ¡æ•°: {statistics.get('average_visible_tasks_per_collection', 0):.2f}\n\n")
                
                f.write("ç›®å½•ç»“æ„:\n")
                directory_structure = session_summary.get("directory_structure", {})
                for key, path in directory_structure.items():
                    f.write(f"  {key}: {path}\n")
                
                f.write("\né‡‡é›†è¯¦æƒ…:\n")
                for collection in session_summary.get("collections", []):
                    f.write(f"  ç¬¬{collection.get('collection_index', 0)}æ¬¡é‡‡é›†: {collection.get('collection_time', '')}\n")
            
            logger.info(f"ğŸ“‹ ä¼šè¯æ±‡æ€»å·²ä¿å­˜:")
            logger.info(f"   JSONæ ¼å¼: {summary_file}")
            logger.info(f"   æ–‡æœ¬æ ¼å¼: {text_summary_file}")
            
            return str(summary_file)
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜ä¼šè¯æ±‡æ€»å¤±è´¥: {e}")
            return None
    
    def _extract_timeline_data(self, collection_result: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """ä»é‡‡é›†ç»“æœä¸­æå–æ—¶é—´è½´æ•°æ®"""
        try:
            from src.utils.timeline_converter import TimelineConverter
            
            converter = TimelineConverter()
            timeline_data = converter.convert_collection_data(collection_result)
            
            return timeline_data
            
        except Exception as e:
            logger.warning(f"âš ï¸ æå–æ—¶é—´è½´æ•°æ®å¤±è´¥: {e}")
            return None
    
    def _create_collection_summary(self, collection_index: int, collection_result: Dict[str, Any], 
                                 conflict_resolution_data: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """åˆ›å»ºå•æ¬¡é‡‡é›†çš„æ‘˜è¦æ•°æ®"""
        try:
            # åŸºç¡€ä¿¡æ¯
            rolling_info = collection_result.get("rolling_collection_info", {})
            
            # å…ƒä»»åŠ¡ç»Ÿè®¡
            meta_tasks = collection_result.get("meta_tasks", {}).get("meta_tasks", {})
            total_meta_tasks = sum(len(missile_data.get("atomic_tasks", [])) for missile_data in meta_tasks.values())
            total_real_tasks = sum(missile_data.get("real_task_count", 0) for missile_data in meta_tasks.values())
            total_virtual_tasks = sum(missile_data.get("virtual_task_count", 0) for missile_data in meta_tasks.values())
            
            # å¯è§ä»»åŠ¡ç»Ÿè®¡
            visible_meta_tasks = collection_result.get("visible_meta_tasks", {})
            constellation_sets = visible_meta_tasks.get("constellation_visible_task_sets", {})
            total_visible_tasks = sum(
                len(satellite_data.get("missile_tasks", {}).get(missile_id, {}).get("visible_tasks", []))
                for satellite_data in constellation_sets.values()
                for missile_id in satellite_data.get("missile_tasks", {})
            )
            total_virtual_visible_tasks = sum(
                len(satellite_data.get("missile_tasks", {}).get(missile_id, {}).get("virtual_tasks", []))
                for satellite_data in constellation_sets.values()
                for missile_id in satellite_data.get("missile_tasks", {})
            )
            
            summary = {
                "collection_info": {
                    "index": collection_index,
                    "time": collection_result.get("collection_time", ""),
                    "midcourse_missiles": rolling_info.get("midcourse_missiles", []),
                    "total_missiles_in_scenario": rolling_info.get("total_missiles_in_scenario", 0)
                },
                "statistics": {
                    "total_missiles": len(meta_tasks),
                    "total_meta_tasks": total_meta_tasks,
                    "total_real_tasks": total_real_tasks,
                    "total_virtual_tasks": total_virtual_tasks,
                    "total_satellites": len(constellation_sets),
                    "total_visible_tasks": total_visible_tasks,
                    "total_virtual_visible_tasks": total_virtual_visible_tasks
                },
                "conflict_resolution": {
                    "data_available": conflict_resolution_data is not None,
                    "enhanced_with_positions": conflict_resolution_data.get("metadata", {}).get("conflict_resolution_info", {}).get("position_data_included", False) if conflict_resolution_data else False,
                    "timeline_complete": conflict_resolution_data.get("metadata", {}).get("conflict_resolution_info", {}).get("timeline_complete", False) if conflict_resolution_data else False
                } if conflict_resolution_data else {"data_available": False}
            }
            
            return summary
            
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºé‡‡é›†æ‘˜è¦å¤±è´¥: {e}")
            return {}
